# -*- coding: utf-8 -*-
"""CarbonFootprint.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iH8C7_cYc6Qt5avb1LVT1KGGWNtxzBaD
"""

# Step 1: Load and Preprocess Data
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Load dataset
df = pd.read_csv("/content/improved_customer_carbon_footprint_dataset.csv")

# Encode categorical variable
le = LabelEncoder()
df['Preferred_Packaging'] = le.fit_transform(df['Preferred_Packaging'])

# Features and target
X = df.drop(columns=['Customer_ID', 'Est_CO2e_kg'])
y = df['Est_CO2e_kg']

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Step 2: Train Gradient Boosting with Hyperparameter Tuning
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV

# Define pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', GradientBoostingRegressor(random_state=42))
])

# Define hyperparameter grid
param_grid = {
    'model__n_estimators': [100, 150],
    'model__learning_rate': [0.05, 0.1],
    'model__max_depth': [3, 4],
    'model__subsample': [0.8, 1.0]
}

# Run GridSearchCV
grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=1)
grid_search.fit(X_train, y_train)

# Best model
best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Step 3: Evaluate and Plot Feature Importance
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# Evaluate performance
y_pred = best_model.predict(X_test)
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("R2 Score:", r2_score(y_test, y_pred))

# Plot feature importance
model = best_model.named_steps['model']
importances = model.feature_importances_
features = X.columns

plt.figure(figsize=(10, 6))
sns.barplot(x=importances, y=features)
plt.title("Feature Importance - Gradient Boosting")
plt.xlabel("Importance")
plt.tight_layout()
plt.grid(True)
plt.show()

# Step 4: Predict for a New Customer
new_customer = pd.DataFrame([{
    'Total_Purchases': 15,
    'Avg_Distance_km': 450,
    'Preferred_Packaging': le.transform(['Cardboard'])[0],
    'Returns_%': 3,
    'Electricity_kWh': 320,
    'Travel_km': 1000,
    'Service_Usage_hr': 25
}])

prediction = best_model.predict(new_customer)[0]
print("Estimated Carbon Footprint (kg CO2e):", round(prediction))

# Step 5: Save and Load the Model
import joblib

# Save model
joblib.dump(best_model, "carbon_footprint_model.joblib")

# Load model
loaded_model = joblib.load("carbon_footprint_model.joblib")
pred_loaded = loaded_model.predict(new_customer)[0]
print("Prediction from loaded model:", round(pred_loaded))