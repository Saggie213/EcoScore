# -*- coding: utf-8 -*-
"""Packaging.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pb4i1wa2CHWp_UIzakrL9k_BldUUh15a
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Load dataset
df = pd.read_csv("/content/improved_packaging_suggestion_dataset.csv")

# Encode categorical columns
categorical_cols = ['Material_Type', 'Fragility', 'Recyclable', 'Transport_Mode']
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Encode target
target_encoder = LabelEncoder()
df['Packaging_Option'] = target_encoder.fit_transform(df['Packaging_Option'])

# Features and target
X = df.drop(columns=['Product_ID', 'Packaging_Option'])
y = df['Packaging_Option']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV

# Define pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', GradientBoostingClassifier(random_state=42))
])

# Hyperparameter grid
param_grid = {
    'classifier__n_estimators': [100, 150],
    'classifier__learning_rate': [0.05, 0.1],
    'classifier__max_depth': [3, 4],
    'classifier__subsample': [0.8, 1.0]
}

# Grid Search
grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)
grid_search.fit(X_train, y_train)

# Best model
best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

from sklearn.metrics import classification_report, accuracy_score

# Predictions
y_pred = best_model.predict(X_test)

# Evaluation
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
import seaborn as sns

# Permutation importance (after training)
result = permutation_importance(best_model.named_steps['classifier'], X_test, y_test, n_repeats=10, random_state=42)

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(x=result.importances_mean, y=X.columns)
plt.title("Permutation Feature Importance")
plt.xlabel("Mean Importance")
plt.tight_layout()
plt.show()

# Sample new product data (same feature order as training data)
new_data = pd.DataFrame([{
    'Material_Type': label_encoders['Material_Type'].transform(['Glass'])[0],
    'Product_Weight_g': 150,
    'Fragility': label_encoders['Fragility'].transform(['High'])[0],
    'Recyclable': label_encoders['Recyclable'].transform(['Yes'])[0],
    'Transport_Mode': label_encoders['Transport_Mode'].transform(['Land'])[0],
    'LCA_Emission_kgCO2': 1.89
}])

# Predict
predicted_label = best_model.predict(new_data)[0]
predicted_packaging = target_encoder.inverse_transform([predicted_label])[0]

print("Suggested Packaging Option:", predicted_packaging)